{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Universidad de Buenos Aires\n",
        "# Aprendizaje Profundo - TP1\n",
        "# Cohorte 22 - 5to bimestre 2025\n"
      ],
      "metadata": {
        "id": "tHbzg4F1fLo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este primer TP comienza la semana de la clase 2 y la ventana de entrega estará abierta hasta las **23hs del viernes 14 de noviembre (hora de Argentina)**. La resolución del TP es **individual**. Pueden utilizar tanto los contenidos vistos en clase, como otra bibliografía externa. Si se toman ideas de fuentes externas deben ser correctamente citadas incluyendo el correspondiente link o página de libro.\n",
        "\n",
        "ESTE TP1 EQUIVALE AL 33.33% DE SU NOTA FINAL.\n",
        "\n",
        "El formato de entrega debe ser un link a un notebook de google colab. Importante permitir acceso a gvilcamiza.ext@fi.uba.ar y **habilitar los comentarios, para poder darles el feedback**. Si no lo hacen así no se podrá dar el feedback respectivo por cada pregunta.\n",
        "\n",
        "El envío **se realizará en el siguiente link de google forms: [link](https://forms.gle/98W6TBHjyWnwAzTB9)**. Tanto los resultados, gráficas, como el código y las explicaciones deben quedar guardados y visualizables en el colab.\n",
        "\n",
        "**NO SE VALIDARÁN ENVÍOS POR CORREO, EL MÉTODO DE ENTREGA ES SOLO POR EL FORMS.**\n",
        "\n",
        "**Consideraciones a tener en cuenta:**\n",
        "- Se entregará 1 solo colab para este TP1.\n",
        "- Renombrar el archivo de la siguiente manera: **APELLIDO-NOMBRE-DL-TP1-Co22.ipynb**\n",
        "- Los códigos deben poder ejecutarse.\n",
        "- **IMPORTANTE:** Los resultados, cómo el código, los gráficos, los prints y las explicaciones deben quedar guardados y visualizables en el mismo notebook.\n",
        "- **Prestar mucha atención a cada consigna, responder las preguntas justo debajo del enunciado que corresponda.**\n",
        "- Solo se revisarán los trabajos que hayan sido enviados por el forms."
      ],
      "metadata": {
        "id": "PEib4WVwfQYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREGUNTA 1** (Temas de la clase 1 y 2)"
      ],
      "metadata": {
        "id": "bdseNqG3m7xX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparación de Gradiente Descendente y Adam en una Función de Costo No Convexa**\n",
        "\n",
        "En este ejercicio se compararán los optimizadores Gradiente Descendente (GD) y Adam en la minimización de una función de costo basada en una red neuronal de una sola neurona:\n",
        "$$\n",
        "z = w x + b\n",
        "$$\n",
        "Con función de activación tangente hiperbólica:\n",
        "\n",
        "$$\n",
        "\\hat{y} = a(z) = \\tanh(z) = \\tanh(w x + b)\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "Se analizará la trayectoria de aprendizaje de ambos algoritmos y se evaluará su eficiencia con diferentes tasas de aprendizaje (learning rate).\n",
        "\n",
        "<br>\n",
        "\n",
        "La función de costo utilizada es el Error Cuadrático Medio (MSE):\n",
        "\n",
        "$$\n",
        "J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "J(w, b) = \\frac{1}{m} \\sum_{i=1}^{m} ( \\tanh(w x_i + b) - y_i )^2\n",
        "$$\n",
        "\n",
        "donde \\\\( w \\\\) y \\\\( b \\\\) son los parámetros a optimizar.\n",
        "\n",
        "<br>\n",
        "\n",
        "Si bien es cierto, en estos experimentos estamos comparando optimizadores (GD vs Adam), y no entrenando un modelo como tal, de igual forma se necesitará una especie de dataset. Este será sintético y solo de prueba, por ende tendrán cierta libertad para elegir sus valores. Sin embargo deberán tomar en cuenta que cumpla la siguiente estructura:\n",
        "\n",
        "`x = np.linspace(ini, fin, n)`\n",
        "\n",
        "donde `x` es un array de una sola dimensión y con `n` cantidad de valores ($n>=200$). Y tiene un rango de valores desde `ini` hasta `fin`. Recomiendo que sea simétrico, es decir, los mismos valores solo que con el signo cambiado, por ejemplo `ini=-3, fin=3`.\n",
        "\n",
        "<br>\n",
        "\n",
        "Y con un target `y`:\n",
        "\n",
        "`y = funcion_no_lineal(x) + ruido`\n",
        "\n",
        "donde `y` es también un vector de una sola dimensión de tamaño `n` que sigue un patrón no lineal (elegido por ustedes) con respecto a `x` adicionando un ruido que puede ser creado con algunas de las funciones del paquete `np.random`.\n",
        "\n",
        "El patrón no lineal puede ser una función trigonométrica, exponencial, logarítmica, sigmoidal o polinómica de grado mayor o igual a 3."
      ],
      "metadata": {
        "id": "2gZB6LL8nY3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a) Implementación del Gradiente Descendente (1 punto)\n",
        "- Implementar el algoritmo del Gradiente Descendente (GD) para minimizar \\\\( J(w, b) \\\\).\n",
        "- Utilizar 100 épocas y 3 diferentes learning rates `(0.1, 0.01, 0.001)`.\n",
        "- Inicializar valores de \\\\( w \\\\) y \\\\( b \\\\) de manera aleatoria con `np.random.randn()`.\n",
        "- Graficar la función de Costo \\\\( J(w, b) \\\\) VS número de época para comparar cómo converge la función para los 3 learning rates.\n",
        "\n",
        "<br>\n",
        "\n",
        "El optimizador del Gradiente Descendente se debe implementar haciendo el código desde cero y paso a paso. Se pueden usar librerías como `numpy`, `scipy`, `matplotlib` o similares. Pero no está permitido usar Pytorch ni TensorFlow o frameworks que ya contengan el optimizador desarrollado."
      ],
      "metadata": {
        "id": "Tisjrq4koqV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b) Implementación de Adam (2 punto)  \n",
        "- Implementar el algoritmo de Adam para minimizar \\\\( J(w, b) \\\\).  \n",
        "- Utilizar 100 épocas y 3 diferentes learning rates `(0.1, 0.01, 0.001)`.\n",
        "- Utilizar los mismos valores de \\\\( w \\\\) y \\\\( b \\\\) que se usaron para GD.\n",
        "- Hacer 2 modelos, uno sin mini-batch (full-batch) y otro con mini-batch.\n",
        "- El batch size es a elección de ustedes, pero debe ser mayor o igual a 16.\n",
        "- Graficar la función de Costo \\\\( J(w, b) \\\\) VS número de época para comparar cómo converge la función para ambos modelos y para los 3 learning rates.\n",
        "\n",
        "<br>\n",
        "\n",
        "Al igual que para GD, el optimizador Adam también se debe implementar desde cero y paso a paso. Se pueden usar librerías como `numpy`, `scipy`, `matplotlib` o similares. Pero no está permitido usar Pytorch ni TensorFlow o frameworks que ya contengan el optimizador desarrollado."
      ],
      "metadata": {
        "id": "BJnTd5HurMKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1c) Comparativa de optimizadores (0.5 puntos)  \n",
        "- Comparar el resultado y rendimiento de GD VS Adam (full-batch) VS Adam (mini-batch) para cada uno de los learning rates por separado. Hacerlo con gráficas y tablas.\n",
        "- Redactar conclusiones analíticas que resalten las diferencias entre cada optimizador."
      ],
      "metadata": {
        "id": "nD37r43DWg4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1d) Visualización en 3D de la trayectoria de aprendizaje (0.5 puntos)\n",
        "- Graficar en 3D la trayectoria del aprendizaje de los 3 optimizadores sobre la superficie de la función de costo \\\\( J(w, b) \\\\). Se debe elegir un solo learning rate.\n",
        "- Comparar y redactar cómo se mueven en el espacio de parámetros y qué diferencias existen en la convergencia.\n",
        "- Recomiendo utilizar `mpl_toolkits.mplot3d` y `np.meshgrid`, pero queda a su criterio la elección de funciones a usar para lograr el gráfico."
      ],
      "metadata": {
        "id": "SjvhTH_ZrWAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **RECOMENDACIÓN**:\n",
        "\n",
        "Les recomiendo revisar el notebook sobre optimizadores que se encuentra en el repo. Pueden acceder mediante el siguiente [enlace](https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/aprendizaje_profundo/blob/ap_2026/CLASE%202/Notebooks/clase2_4_optimizadores.ipynb). En ese notebook vemos cómo aplicar GD y Adam full-batch para una red con relación lineal. Les servirá mucho como guía para realizar esta pregunta.\n",
        "\n",
        "Además, también tienen disponible el siguiente [material adicional del repo](https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/aprendizaje_profundo/tree/ap_2026/CLASE%202/Teoria/Material%20adicional), el cual le servirá para aplicar Adam, ya no solo en su versión full-batch, sino también en mini-batch"
      ],
      "metadata": {
        "id": "z6XIdYjnP0w2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREGUNTA 2** (Temas de la clase 3)"
      ],
      "metadata": {
        "id": "BZW4D_PyWq_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caso: Predicción del gasto promedio de los usuarios usando redes neuronales\n",
        "\n",
        "**Descarga del dataset:**  \n",
        "El conjunto de datos puede descargarse en el siguiente [enlace](https://drive.google.com/file/d/1e_FRepCpHBWWGj3TYG4HY7WHALCyR4wQ/view?usp=sharing)\n",
        "\n",
        "---\n",
        "\n",
        "## Descripción general:\n",
        "\n",
        "El dataset recopila información sobre las compras realizadas por distintos clientes en una tienda durante el último año.  \n",
        "Cada registro representa una transacción e incluye datos tanto del cliente como del producto adquirido.\n",
        "\n",
        "---\n",
        "\n",
        "## El dataset contiene la siguiente información:\n",
        "\n",
        "- **User_ID:** Código identificador único del cliente que efectuó la compra.  \n",
        "- **Product_ID:** Código identificador único del producto adquirido.  \n",
        "- **Age:** Rango de edad del cliente.  \n",
        "- **Gender:** Género del cliente (F: Femenino, M: Masculino).  \n",
        "- **Marital_Status:** Estado civil del cliente (0: Soltero, 1: Casado).  \n",
        "- **City_Category:** Tipo de zona donde se encuentra la sucursal donde se realizó la compra.  \n",
        "  - A: Barrio de clase alta  \n",
        "  - B: Barrio de clase media  \n",
        "  - C: Barrio de clase media-baja  \n",
        "- **Stay_In_Current_City_Years:** Número de años que el cliente ha venido comprando en la tienda desde su primera visita.  \n",
        "- **Product_Category:** Categoría del producto comprado.  \n",
        "- **Product_Subcategory_1:** Subcategoría principal del producto.  \n",
        "- **Product_Subcategory_2:** Subcategoría secundaria del producto.  \n",
        "- **Purchase:** Monto pagado por el producto en esa transacción.\n",
        "\n",
        "---\n",
        "\n",
        "## Objetivo del caso de estudio:\n",
        "\n",
        "Desarrollar un **modelo predictivo** capaz de estimar el **gasto promedio** que realizará un cliente, a partir de su información demográfica y sus patrones de compra.\n"
      ],
      "metadata": {
        "id": "CKl9cz2BWuUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a) EDA y preparación del dataset (2 puntos)\n",
        "Realizar el análisis exploratorio del dataset (EDA) con las herramientas vistas en materias anteriores.\n",
        "- Analizar qué columnas sirven para lograr el objetivo y cuáles no (drop) en base al contexto del negocio y a lo entendido del caso de estudio (feature engineering).\n",
        "- Analizar con qué columnas vale la pena hacer un tratamiento de valores nulos o si simplemente se debe dropear toda la columna porque ya no tiene salvación.\n",
        "- Analizar a qué variables se les debe hacer label encoding, a cuáles one-hot encoding, ordinal encoding o mapping encoding. Explicar los criterios utilizados para tomar esas decisiones.\n",
        "- Transformar, agrupar, combinar y operar la data de tal manera que sea útil para extraer patrones de gastos y tendencias de gustos del cliente.\n",
        "\n",
        "\n",
        "\n",
        "Redactar las conclusiones preliminares que puedan notar de cada feature y justificar el porqué de cada encoding, limpieza o transformación aplicada. Cada justificación se debe redactar a detalle y sustentar con gráficas y/o tablas.\n"
      ],
      "metadata": {
        "id": "ra5HodW2ir2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2b) Modelo Multilayer Perceptron (MLP) (2.5 puntos)\n",
        "Entrenar un modelo de deep learning usando PyTorch que consuma el dataframe ya pre-procesado en el paso anterior.\n",
        "\n",
        "Características para el diseño de la red:\n",
        "- El modelo debe tener un mínimo de 3 capas ocultas.\n",
        "- El modelo debe tener un mínimo de 32 neuronas por cada capa oculta.\n",
        "- Cada capa oculta debe tener su respectiva función de activación.\n",
        "- La elección de la función de activación de las capas ocultas es libre, pero se debe justificar por qué se está eligiendo esa, ya sea mediante conceptos teóricos o con resultados de pruebas empíricas.\n",
        "- Analizar y justificar cuál es la mejor función de costo, algoritmo de optimización y learning rate para este modelo.\n",
        "- Analizar cuál sería el mejor número de épocas para entrenar el modelo.\n",
        "- Opcional: Incluir técnicas de regularización como dropout en las capas ocultas."
      ],
      "metadata": {
        "id": "4QCKMGGmlCA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2c) Evaluación del Modelo (1 punto)\n",
        "- Graficar las evoluciones por época de la función de costo y del $R^2$, tanto para el set de train como el de validation.\n",
        "- Gráfica scatter de Real VS Predicho en el set de validation.\n",
        "- Explicar el proceso de iteracion utilizado para conseguir los mejores resultados y justificar los resultados obtenidos.\n",
        "- Un resultado aceptable sería un $R^2$ de al menos 0.55 para el set de validation."
      ],
      "metadata": {
        "id": "UrWOf4z-lakA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2d) Conclusiones finales (0.5 puntos)\n",
        "Redactar de manera detallada las conclusiones finales y si se cumplió con el objetivo o no."
      ],
      "metadata": {
        "id": "0csdYKtil1t1"
      }
    }
  ]
}